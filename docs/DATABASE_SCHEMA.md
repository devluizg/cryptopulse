# üóÑÔ∏è CryptoPulse - Schema do Banco de Dados

## Vis√£o Geral

O CryptoPulse utiliza **PostgreSQL 16** como banco de dados principal. Este documento descreve todas as tabelas, relacionamentos, √≠ndices e queries √∫teis.

---

## √çndice

1. [Diagrama ER](#diagrama-er)
2. [Tabelas](#tabelas)
3. [Queries √öteis](#queries-√∫teis)
4. [Manuten√ß√£o](#manuten√ß√£o)
5. [Migra√ß√µes](#migra√ß√µes)
6. [Performance](#performance)

---

## Diagrama ER

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    assets       ‚îÇ         ‚îÇ   price_data    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§         ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ id (PK)         ‚îÇ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ id (PK)         ‚îÇ
‚îÇ symbol          ‚îÇ   ‚îÇ     ‚îÇ asset_id (FK)   ‚îÇ‚îÄ‚îÄ‚îê
‚îÇ name            ‚îÇ   ‚îÇ     ‚îÇ price           ‚îÇ  ‚îÇ
‚îÇ is_active       ‚îÇ   ‚îÇ     ‚îÇ volume_24h      ‚îÇ  ‚îÇ
‚îÇ created_at      ‚îÇ   ‚îÇ     ‚îÇ market_cap      ‚îÇ  ‚îÇ
‚îÇ updated_at      ‚îÇ   ‚îÇ     ‚îÇ price_change_24h‚îÇ  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ     ‚îÇ recorded_at     ‚îÇ  ‚îÇ
                      ‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
                      ‚îÇ                          ‚îÇ
                      ‚îÇ     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
                      ‚îÇ     ‚îÇ  asset_scores   ‚îÇ  ‚îÇ
                      ‚îÇ     ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  ‚îÇ
                      ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ id (PK)         ‚îÇ  ‚îÇ
                      ‚îÇ     ‚îÇ asset_id (FK)   ‚îÇ‚îÄ‚îÄ‚î§
                      ‚îÇ     ‚îÇ explosion_score ‚îÇ  ‚îÇ
                      ‚îÇ     ‚îÇ whale_score     ‚îÇ  ‚îÇ
                      ‚îÇ     ‚îÇ volume_score    ‚îÇ  ‚îÇ
                      ‚îÇ     ‚îÇ netflow_score   ‚îÇ  ‚îÇ
                      ‚îÇ     ‚îÇ oi_score        ‚îÇ  ‚îÇ
                      ‚îÇ     ‚îÇ narrative_score ‚îÇ  ‚îÇ
                      ‚îÇ     ‚îÇ status          ‚îÇ  ‚îÇ
                      ‚îÇ     ‚îÇ reasons         ‚îÇ  ‚îÇ
                      ‚îÇ     ‚îÇ calculated_at   ‚îÇ  ‚îÇ
                      ‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
                      ‚îÇ                          ‚îÇ
                      ‚îÇ     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
                      ‚îÇ     ‚îÇ     alerts      ‚îÇ  ‚îÇ
                      ‚îÇ     ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§  ‚îÇ
                      ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ id (PK)         ‚îÇ  ‚îÇ
                      ‚îÇ     ‚îÇ asset_id (FK)   ‚îÇ‚îÄ‚îÄ‚î§
                      ‚îÇ     ‚îÇ alert_type      ‚îÇ  ‚îÇ
                      ‚îÇ     ‚îÇ title           ‚îÇ  ‚îÇ
                      ‚îÇ     ‚îÇ message         ‚îÇ  ‚îÇ
                      ‚îÇ     ‚îÇ severity        ‚îÇ  ‚îÇ
                      ‚îÇ     ‚îÇ status          ‚îÇ  ‚îÇ
                      ‚îÇ     ‚îÇ metadata        ‚îÇ  ‚îÇ
                      ‚îÇ     ‚îÇ created_at      ‚îÇ  ‚îÇ
                      ‚îÇ     ‚îÇ read_at         ‚îÇ  ‚îÇ
                      ‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
                      ‚îÇ                          ‚îÇ
                      ‚îÇ     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
                      ‚îÇ     ‚îÇwhale_transactions ‚îÇ‚îÇ
                      ‚îÇ     ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§‚îÇ
                      ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ id (PK)           ‚îÇ‚îÇ
                      ‚îÇ     ‚îÇ asset_id (FK)     ‚îÇ‚îò
                      ‚îÇ     ‚îÇ tx_hash           ‚îÇ
                      ‚îÇ     ‚îÇ from_address      ‚îÇ
                      ‚îÇ     ‚îÇ to_address        ‚îÇ
                      ‚îÇ     ‚îÇ amount            ‚îÇ
                      ‚îÇ     ‚îÇ amount_usd        ‚îÇ
                      ‚îÇ     ‚îÇ tx_type           ‚îÇ
                      ‚îÇ     ‚îÇ blockchain        ‚îÇ
                      ‚îÇ     ‚îÇ recorded_at       ‚îÇ
                      ‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
                      ‚îÇ     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                      ‚îÇ     ‚îÇ exchange_flows  ‚îÇ
                      ‚îÇ     ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
                      ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ id (PK)         ‚îÇ
                      ‚îÇ     ‚îÇ asset_id (FK)   ‚îÇ
                      ‚îÇ     ‚îÇ exchange        ‚îÇ
                      ‚îÇ     ‚îÇ inflow          ‚îÇ
                      ‚îÇ     ‚îÇ outflow         ‚îÇ
                      ‚îÇ     ‚îÇ netflow         ‚îÇ
                      ‚îÇ     ‚îÇ recorded_at     ‚îÇ
                      ‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
                      ‚îÇ     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                      ‚îÇ     ‚îÇnarrative_events  ‚îÇ
                      ‚îÇ     ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
                      ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ id (PK)          ‚îÇ
                      ‚îÇ     ‚îÇ asset_id (FK)    ‚îÇ
                      ‚îÇ     ‚îÇ title            ‚îÇ
                      ‚îÇ     ‚îÇ source           ‚îÇ
                      ‚îÇ     ‚îÇ url              ‚îÇ
                      ‚îÇ     ‚îÇ sentiment        ‚îÇ
                      ‚îÇ     ‚îÇ importance       ‚îÇ
                      ‚îÇ     ‚îÇ published_at     ‚îÇ
                      ‚îÇ     ‚îÇ recorded_at      ‚îÇ
                      ‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ
                      ‚îÇ     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                      ‚îÇ     ‚îÇmetric_snapshots  ‚îÇ
                      ‚îÇ     ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
                      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ id (PK)          ‚îÇ
                            ‚îÇ asset_id (FK)    ‚îÇ
                            ‚îÇ metric_type      ‚îÇ
                            ‚îÇ value            ‚îÇ
                            ‚îÇ metadata         ‚îÇ
                            ‚îÇ recorded_at      ‚îÇ
                            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Tabelas

### 1. assets

**Descri√ß√£o:** Criptomoedas monitoradas pelo sistema.

```sql
CREATE TABLE assets (
    id SERIAL PRIMARY KEY,
    symbol VARCHAR(20) NOT NULL UNIQUE,
    name VARCHAR(100) NOT NULL,
    is_active BOOLEAN DEFAULT true,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- √çndices
CREATE INDEX idx_assets_symbol ON assets(symbol);
CREATE INDEX idx_assets_active ON assets(is_active);

-- Trigger para updated_at
CREATE TRIGGER update_assets_updated_at
    BEFORE UPDATE ON assets
    FOR EACH ROW
    EXECUTE FUNCTION update_updated_at_column();
```

#### Colunas

| Coluna | Tipo | Restri√ß√µes | Descri√ß√£o |
|--------|------|------------|-----------|
| `id` | SERIAL | PRIMARY KEY | Identificador √∫nico |
| `symbol` | VARCHAR(20) | NOT NULL, UNIQUE | S√≠mbolo do ativo (BTC, ETH) |
| `name` | VARCHAR(100) | NOT NULL | Nome completo do ativo |
| `is_active` | BOOLEAN | DEFAULT true | Se est√° sendo monitorado |
| `created_at` | TIMESTAMP | DEFAULT NOW() | Data de cria√ß√£o |
| `updated_at` | TIMESTAMP | DEFAULT NOW() | √öltima atualiza√ß√£o |

#### Exemplo de Dados

```sql
INSERT INTO assets (symbol, name) VALUES
    ('BTC', 'Bitcoin'),
    ('ETH', 'Ethereum'),
    ('SOL', 'Solana');
```

---

### 2. asset_scores

**Descri√ß√£o:** Scores calculados para cada ativo pelo engine de an√°lise.

```sql
CREATE TABLE asset_scores (
    id SERIAL PRIMARY KEY,
    asset_id INTEGER NOT NULL REFERENCES assets(id) ON DELETE CASCADE,
    explosion_score DECIMAL(5,2) CHECK (explosion_score >= 0 AND explosion_score <= 100),
    whale_score DECIMAL(5,2) CHECK (whale_score >= 0 AND whale_score <= 100),
    volume_score DECIMAL(5,2) CHECK (volume_score >= 0 AND volume_score <= 100),
    netflow_score DECIMAL(5,2) CHECK (netflow_score >= 0 AND netflow_score <= 100),
    oi_score DECIMAL(5,2) CHECK (oi_score >= 0 AND oi_score <= 100),
    narrative_score DECIMAL(5,2) CHECK (narrative_score >= 0 AND narrative_score <= 100),
    status VARCHAR(20) DEFAULT 'low' CHECK (status IN ('low', 'attention', 'high')),
    reasons JSONB DEFAULT '[]',
    calculated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- √çndices
CREATE INDEX idx_asset_scores_asset_id ON asset_scores(asset_id);
CREATE INDEX idx_asset_scores_calculated_at ON asset_scores(calculated_at DESC);
CREATE INDEX idx_asset_scores_status ON asset_scores(status);
CREATE INDEX idx_asset_scores_explosion_score ON asset_scores(explosion_score DESC);

-- √çndice composto para queries frequentes
CREATE INDEX idx_asset_scores_asset_time ON asset_scores(asset_id, calculated_at DESC);
```

#### Colunas

| Coluna | Tipo | Restri√ß√µes | Descri√ß√£o |
|--------|------|------------|-----------|
| `id` | SERIAL | PRIMARY KEY | Identificador √∫nico |
| `asset_id` | INTEGER | FK, NOT NULL | Refer√™ncia ao ativo |
| `explosion_score` | DECIMAL(5,2) | 0-100 | Score final ponderado |
| `whale_score` | DECIMAL(5,2) | 0-100 | Score de atividade de whales |
| `volume_score` | DECIMAL(5,2) | 0-100 | Score de volume |
| `netflow_score` | DECIMAL(5,2) | 0-100 | Score de fluxo de exchanges |
| `oi_score` | DECIMAL(5,2) | 0-100 | Score de Open Interest |
| `narrative_score` | DECIMAL(5,2) | 0-100 | Score de narrativa/not√≠cias |
| `status` | VARCHAR(20) | low/attention/high | Status do score |
| `reasons` | JSONB | Array | Motivos do score |
| `calculated_at` | TIMESTAMP | DEFAULT NOW() | Momento do c√°lculo |

#### Status

| Status | Range | Descri√ß√£o |
|--------|-------|-----------|
| `low` | 0-49 | Score baixo, sem alerta |
| `attention` | 50-69 | Score m√©dio, aten√ß√£o |
| `high` | 70-100 | Score alto, alerta |

#### Exemplo de Reasons (JSONB)

```json
[
  "Alta atividade de whales nas √∫ltimas 24h",
  "Volume 150% acima da m√©dia",
  "Open Interest crescente",
  "Sentimento positivo em not√≠cias"
]
```

---

### 3. alerts

**Descri√ß√£o:** Alertas gerados pelo sistema baseados em thresholds e eventos.

```sql
CREATE TABLE alerts (
    id SERIAL PRIMARY KEY,
    asset_id INTEGER REFERENCES assets(id) ON DELETE SET NULL,
    alert_type VARCHAR(50) NOT NULL,
    title VARCHAR(200) NOT NULL,
    message TEXT,
    severity VARCHAR(20) DEFAULT 'info' CHECK (severity IN ('info', 'warning', 'critical')),
    status VARCHAR(20) DEFAULT 'pending' CHECK (status IN ('pending', 'sent', 'read', 'dismissed')),
    metadata JSONB DEFAULT '{}',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    read_at TIMESTAMP WITH TIME ZONE
);

-- √çndices
CREATE INDEX idx_alerts_asset_id ON alerts(asset_id);
CREATE INDEX idx_alerts_status ON alerts(status);
CREATE INDEX idx_alerts_severity ON alerts(severity);
CREATE INDEX idx_alerts_created_at ON alerts(created_at DESC);
CREATE INDEX idx_alerts_type ON alerts(alert_type);

-- √çndice para alertas n√£o lidos
CREATE INDEX idx_alerts_unread ON alerts(status) WHERE status = 'pending';
```

#### Colunas

| Coluna | Tipo | Restri√ß√µes | Descri√ß√£o |
|--------|------|------------|-----------|
| `id` | SERIAL | PRIMARY KEY | Identificador √∫nico |
| `asset_id` | INTEGER | FK, NULLABLE | Ativo relacionado (pode ser NULL) |
| `alert_type` | VARCHAR(50) | NOT NULL | Tipo do alerta |
| `title` | VARCHAR(200) | NOT NULL | T√≠tulo do alerta |
| `message` | TEXT | NULLABLE | Mensagem detalhada |
| `severity` | VARCHAR(20) | DEFAULT 'info' | Severidade do alerta |
| `status` | VARCHAR(20) | DEFAULT 'pending' | Status do alerta |
| `metadata` | JSONB | DEFAULT '{}' | Dados adicionais |
| `created_at` | TIMESTAMP | DEFAULT NOW() | Data de cria√ß√£o |
| `read_at` | TIMESTAMP | NULLABLE | Quando foi lido |

#### Alert Types

| Type | Descri√ß√£o |
|------|-----------|
| `score_threshold` | Score ultrapassou threshold |
| `whale_alert` | Grande transa√ß√£o detectada |
| `volume_spike` | Pico de volume |
| `price_change` | Mudan√ßa brusca de pre√ßo |
| `netflow_alert` | Fluxo anormal em exchanges |
| `narrative_event` | Evento importante nas not√≠cias |

#### Severity Levels

| Severity | Cor | Uso |
|----------|-----|-----|
| `info` | üîµ Blue | Informativo |
| `warning` | üü° Yellow | Aten√ß√£o |
| `critical` | üî¥ Red | Cr√≠tico |

---

### 4. price_data

**Descri√ß√£o:** Dados hist√≥ricos de pre√ßo e m√©tricas de mercado.

```sql
CREATE TABLE price_data (
    id SERIAL PRIMARY KEY,
    asset_id INTEGER NOT NULL REFERENCES assets(id) ON DELETE CASCADE,
    price DECIMAL(20,8) NOT NULL,
    volume_24h DECIMAL(30,2),
    market_cap DECIMAL(30,2),
    price_change_24h DECIMAL(10,4),
    recorded_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- √çndices
CREATE INDEX idx_price_data_asset_id ON price_data(asset_id);
CREATE INDEX idx_price_data_recorded_at ON price_data(recorded_at DESC);
CREATE INDEX idx_price_data_asset_time ON price_data(asset_id, recorded_at DESC);

-- Particionamento (opcional, para grandes volumes)
-- Particionar por m√™s para melhor performance
```

#### Colunas

| Coluna | Tipo | Restri√ß√µes | Descri√ß√£o |
|--------|------|------------|-----------|
| `id` | SERIAL | PRIMARY KEY | Identificador √∫nico |
| `asset_id` | INTEGER | FK, NOT NULL | Refer√™ncia ao ativo |
| `price` | DECIMAL(20,8) | NOT NULL | Pre√ßo atual em USD |
| `volume_24h` | DECIMAL(30,2) | NULLABLE | Volume em 24h |
| `market_cap` | DECIMAL(30,2) | NULLABLE | Capitaliza√ß√£o de mercado |
| `price_change_24h` | DECIMAL(10,4) | NULLABLE | Mudan√ßa de pre√ßo (%) |
| `recorded_at` | TIMESTAMP | DEFAULT NOW() | Momento da coleta |

---

### 5. whale_transactions

**Descri√ß√£o:** Transa√ß√µes de grandes holders (whales) detectadas on-chain.

```sql
CREATE TABLE whale_transactions (
    id SERIAL PRIMARY KEY,
    asset_id INTEGER NOT NULL REFERENCES assets(id) ON DELETE CASCADE,
    tx_hash VARCHAR(100) UNIQUE NOT NULL,
    from_address VARCHAR(100),
    to_address VARCHAR(100),
    amount DECIMAL(30,8) NOT NULL,
    amount_usd DECIMAL(20,2),
    tx_type VARCHAR(20) CHECK (tx_type IN ('transfer', 'exchange_deposit', 'exchange_withdrawal')),
    blockchain VARCHAR(50),
    recorded_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- √çndices
CREATE INDEX idx_whale_tx_asset_id ON whale_transactions(asset_id);
CREATE INDEX idx_whale_tx_recorded_at ON whale_transactions(recorded_at DESC);
CREATE INDEX idx_whale_tx_type ON whale_transactions(tx_type);
CREATE INDEX idx_whale_tx_hash ON whale_transactions(tx_hash);
CREATE INDEX idx_whale_tx_amount ON whale_transactions(amount_usd DESC);
```

#### Colunas

| Coluna | Tipo | Restri√ß√µes | Descri√ß√£o |
|--------|------|------------|-----------|
| `id` | SERIAL | PRIMARY KEY | Identificador √∫nico |
| `asset_id` | INTEGER | FK, NOT NULL | Refer√™ncia ao ativo |
| `tx_hash` | VARCHAR(100) | UNIQUE, NOT NULL | Hash da transa√ß√£o |
| `from_address` | VARCHAR(100) | NULLABLE | Endere√ßo de origem |
| `to_address` | VARCHAR(100) | NULLABLE | Endere√ßo de destino |
| `amount` | DECIMAL(30,8) | NOT NULL | Quantidade transferida |
| `amount_usd` | DECIMAL(20,2) | NULLABLE | Valor em USD |
| `tx_type` | VARCHAR(20) | NULLABLE | Tipo da transa√ß√£o |
| `blockchain` | VARCHAR(50) | NULLABLE | Blockchain (ethereum, bitcoin) |
| `recorded_at` | TIMESTAMP | DEFAULT NOW() | Momento da detec√ß√£o |

#### Transaction Types

| Type | Descri√ß√£o |
|------|-----------|
| `transfer` | Transfer√™ncia normal |
| `exchange_deposit` | Dep√≥sito em exchange |
| `exchange_withdrawal` | Saque de exchange |

---

### 6. exchange_flows

**Descri√ß√£o:** Fluxo de entrada/sa√≠da de criptomoedas em exchanges.

```sql
CREATE TABLE exchange_flows (
    id SERIAL PRIMARY KEY,
    asset_id INTEGER NOT NULL REFERENCES assets(id) ON DELETE CASCADE,
    exchange VARCHAR(50) NOT NULL,
    inflow DECIMAL(30,8) DEFAULT 0,
    outflow DECIMAL(30,8) DEFAULT 0,
    netflow DECIMAL(30,8) DEFAULT 0,
    recorded_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- √çndices
CREATE INDEX idx_exchange_flows_asset_id ON exchange_flows(asset_id);
CREATE INDEX idx_exchange_flows_recorded_at ON exchange_flows(recorded_at DESC);
CREATE INDEX idx_exchange_flows_exchange ON exchange_flows(exchange);
CREATE INDEX idx_exchange_flows_asset_exchange ON exchange_flows(asset_id, exchange, recorded_at DESC);
```

#### Colunas

| Coluna | Tipo | Restri√ß√µes | Descri√ß√£o |
|--------|------|------------|-----------|
| `id` | SERIAL | PRIMARY KEY | Identificador √∫nico |
| `asset_id` | INTEGER | FK, NOT NULL | Refer√™ncia ao ativo |
| `exchange` | VARCHAR(50) | NOT NULL | Nome da exchange |
| `inflow` | DECIMAL(30,8) | DEFAULT 0 | Entrada na exchange |
| `outflow` | DECIMAL(30,8) | DEFAULT 0 | Sa√≠da da exchange |
| `netflow` | DECIMAL(30,8) | DEFAULT 0 | Fluxo l√≠quido (inflow - outflow) |
| `recorded_at` | TIMESTAMP | DEFAULT NOW() | Momento da coleta |

#### Interpreta√ß√£o do Netflow

| Netflow | Significado |
|---------|-------------|
| Positivo | Mais entrada que sa√≠da (bearish) |
| Negativo | Mais sa√≠da que entrada (bullish) |
| Pr√≥ximo de 0 | Equil√≠brio |

---

### 7. narrative_events

**Descri√ß√£o:** Not√≠cias e eventos relevantes que afetam o sentimento do mercado.

```sql
CREATE TABLE narrative_events (
    id SERIAL PRIMARY KEY,
    asset_id INTEGER REFERENCES assets(id) ON DELETE SET NULL,
    title VARCHAR(500) NOT NULL,
    source VARCHAR(100),
    url VARCHAR(500),
    sentiment VARCHAR(20) CHECK (sentiment IN ('positive', 'negative', 'neutral')),
    importance INTEGER DEFAULT 1 CHECK (importance >= 1 AND importance <= 5),
    published_at TIMESTAMP WITH TIME ZONE,
    recorded_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- √çndices
CREATE INDEX idx_narrative_events_asset_id ON narrative_events(asset_id);
CREATE INDEX idx_narrative_events_published_at ON narrative_events(published_at DESC);
CREATE INDEX idx_narrative_events_sentiment ON narrative_events(sentiment);
CREATE INDEX idx_narrative_events_importance ON narrative_events(importance DESC);
```

#### Colunas

| Coluna | Tipo | Restri√ß√µes | Descri√ß√£o |
|--------|------|------------|-----------|
| `id` | SERIAL | PRIMARY KEY | Identificador √∫nico |
| `asset_id` | INTEGER | FK, NULLABLE | Ativo relacionado |
| `title` | VARCHAR(500) | NOT NULL | T√≠tulo da not√≠cia/evento |
| `source` | VARCHAR(100) | NULLABLE | Fonte (CryptoPanic, NewsAPI) |
| `url` | VARCHAR(500) | NULLABLE | URL da not√≠cia |
| `sentiment` | VARCHAR(20) | NULLABLE | Sentimento da not√≠cia |
| `importance` | INTEGER | DEFAULT 1 | Import√¢ncia (1-5) |
| `published_at` | TIMESTAMP | NULLABLE | Data de publica√ß√£o |
| `recorded_at` | TIMESTAMP | DEFAULT NOW() | Data de coleta |

#### Sentiment

| Sentiment | Descri√ß√£o |
|-----------|-----------|
| `positive` | Not√≠cia positiva/bullish |
| `negative` | Not√≠cia negativa/bearish |
| `neutral` | Not√≠cia neutra |

#### Importance Levels

| Level | Descri√ß√£o | Exemplo |
|-------|-----------|---------|
| 1 | Baixa | Tweet aleat√≥rio |
| 2 | Moderada | Not√≠cia menor |
| 3 | M√©dia | An√∫ncio de projeto |
| 4 | Alta | Partnership grande |
| 5 | Cr√≠tica | Fork, hack, regula√ß√£o |

---

### 8. metric_snapshots

**Descri√ß√£o:** Snapshots de m√©tricas diversas coletadas ao longo do tempo.

```sql
CREATE TABLE metric_snapshots (
    id SERIAL PRIMARY KEY,
    asset_id INTEGER REFERENCES assets(id) ON DELETE CASCADE,
    metric_type VARCHAR(50) NOT NULL,
    value DECIMAL(30,8),
    metadata JSONB DEFAULT '{}',
    recorded_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- √çndices
CREATE INDEX idx_metric_snapshots_asset_id ON metric_snapshots(asset_id);
CREATE INDEX idx_metric_snapshots_type ON metric_snapshots(metric_type);
CREATE INDEX idx_metric_snapshots_recorded_at ON metric_snapshots(recorded_at DESC);
CREATE INDEX idx_metric_snapshots_asset_type ON metric_snapshots(asset_id, metric_type, recorded_at DESC);
```

#### Colunas

| Coluna | Tipo | Restri√ß√µes | Descri√ß√£o |
|--------|------|------------|-----------|
| `id` | SERIAL | PRIMARY KEY | Identificador √∫nico |
| `asset_id` | INTEGER | FK, NULLABLE | Ativo relacionado |
| `metric_type` | VARCHAR(50) | NOT NULL | Tipo da m√©trica |
| `value` | DECIMAL(30,8) | NULLABLE | Valor da m√©trica |
| `metadata` | JSONB | DEFAULT '{}' | Metadados adicionais |
| `recorded_at` | TIMESTAMP | DEFAULT NOW() | Momento da coleta |

#### Metric Types

| metric_type | Descri√ß√£o |
|-------------|-----------|
| `open_interest` | Open Interest de futuros |
| `funding_rate` | Taxa de funding (perpetual) |
| `active_addresses` | Endere√ßos ativos on-chain |
| `hash_rate` | Hash rate (Bitcoin) |
| `tvl` | Total Value Locked (DeFi) |
| `staking_ratio` | % de tokens em staking |
| `circulating_supply` | Supply circulante |

---

## Queries √öteis

### Score mais recente por ativo

```sql
SELECT DISTINCT ON (asset_id)
    a.symbol,
    a.name,
    s.explosion_score,
    s.status,
    s.whale_score,
    s.volume_score,
    s.netflow_score,
    s.oi_score,
    s.narrative_score,
    s.calculated_at
FROM asset_scores s
JOIN assets a ON s.asset_id = a.id
WHERE a.is_active = true
ORDER BY asset_id, calculated_at DESC;
```

### Alertas n√£o lidos

```sql
SELECT 
    al.id,
    a.symbol,
    a.name,
    al.alert_type,
    al.title,
    al.message,
    al.severity,
    al.created_at
FROM alerts al
LEFT JOIN assets a ON al.asset_id = a.id
WHERE al.status = 'pending'
ORDER BY al.severity DESC, al.created_at DESC
LIMIT 50;
```

### Hist√≥rico de score (√∫ltimas 24h)

```sql
SELECT 
    date_trunc('hour', calculated_at) as hour,
    AVG(explosion_score) as avg_score,
    MAX(explosion_score) as max_score,
    MIN(explosion_score) as min_score
FROM asset_scores
WHERE asset_id = (SELECT id FROM assets WHERE symbol = 'BTC')
  AND calculated_at > NOW() - INTERVAL '24 hours'
GROUP BY hour
ORDER BY hour;
```

### Top whales por per√≠odo

```sql
SELECT 
    a.symbol,
    date_trunc('day', wt.recorded_at) as day,
    COUNT(*) as num_transactions,
    SUM(wt.amount_usd) as total_usd,
    AVG(wt.amount_usd) as avg_usd
FROM whale_transactions wt
JOIN assets a ON wt.asset_id = a.id
WHERE wt.recorded_at > NOW() - INTERVAL '7 days'
GROUP BY a.symbol, day
ORDER BY day DESC, total_usd DESC;
```

### Netflow por exchange

```sql
SELECT 
    a.symbol,
    ef.exchange,
    SUM(ef.netflow) as total_netflow,
    AVG(ef.netflow) as avg_netflow
FROM exchange_flows ef
JOIN assets a ON ef.asset_id = a.id
WHERE ef.recorded_at > NOW() - INTERVAL '24 hours'
GROUP BY a.symbol, ef.exchange
ORDER BY total_netflow DESC;
```

### Assets com maior varia√ß√£o de score

```sql
WITH recent_scores AS (
    SELECT DISTINCT ON (asset_id)
        asset_id,
        explosion_score as current_score,
        calculated_at
    FROM asset_scores
    WHERE calculated_at > NOW() - INTERVAL '1 hour'
    ORDER BY asset_id, calculated_at DESC
),
old_scores AS (
    SELECT DISTINCT ON (asset_id)
        asset_id,
        explosion_score as old_score
    FROM asset_scores
    WHERE calculated_at BETWEEN NOW() - INTERVAL '25 hours' 
                            AND NOW() - INTERVAL '23 hours'
    ORDER BY asset_id, calculated_at DESC
)
SELECT 
    a.symbol,
    a.name,
    rs.current_score,
    os.old_score,
    (rs.current_score - os.old_score) as score_change
FROM recent_scores rs
JOIN old_scores os ON rs.asset_id = os.asset_id
JOIN assets a ON rs.asset_id = a.id
WHERE a.is_active = true
ORDER BY ABS(rs.current_score - os.old_score) DESC
LIMIT 10;
```

### Eventos narrativos recentes com alto impacto

```sql
SELECT 
    a.symbol,
    ne.title,
    ne.source,
    ne.sentiment,
    ne.importance,
    ne.published_at
FROM narrative_events ne
LEFT JOIN assets a ON ne.asset_id = a.id
WHERE ne.importance >= 4
  AND ne.published_at > NOW() - INTERVAL '7 days'
ORDER BY ne.importance DESC, ne.published_at DESC
LIMIT 20;
```

---

## Manuten√ß√£o

### Limpeza de Dados Antigos

```sql
-- Remover price_data com mais de 90 dias
DELETE FROM price_data 
WHERE recorded_at < NOW() - INTERVAL '90 days';

-- Remover scores com mais de 30 dias
DELETE FROM asset_scores 
WHERE calculated_at < NOW() - INTERVAL '30 days';

-- Remover alertas lidos com mais de 7 dias
DELETE FROM alerts 
WHERE status IN ('read', 'dismissed')
  AND read_at < NOW() - INTERVAL '7 days';

-- Remover whale transactions com mais de 60 dias
DELETE FROM whale_transactions
WHERE recorded_at < NOW() - INTERVAL '60 days';

-- Remover narrative events com mais de 30 dias
DELETE FROM narrative_events
WHERE recorded_at < NOW() - INTERVAL '30 days';
```

### Vacuum e Analyze

```sql
-- Executar periodicamente para manter performance
VACUUM ANALYZE assets;
VACUUM ANALYZE asset_scores;
VACUUM ANALYZE price_data;
VACUUM ANALYZE whale_transactions;
VACUUM ANALYZE alerts;
VACUUM ANALYZE exchange_flows;
VACUUM ANALYZE narrative_events;
VACUUM ANALYZE metric_snapshots;

-- Ou executar em todas as tabelas
VACUUM ANALYZE;
```

### Reindexa√ß√£o

```sql
-- Se √≠ndices ficarem fragmentados
REINDEX TABLE asset_scores;
REINDEX TABLE price_data;
REINDEX TABLE whale_transactions;
```

### Estat√≠sticas da Database

```sql
-- Tamanho das tabelas
SELECT 
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size
FROM pg_tables
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;

-- N√∫mero de registros por tabela
SELECT 
    schemaname,
    tablename,
    n_tup_ins as inserts,
    n_tup_upd as updates,
    n_tup_del as deletes,
    n_live_tup as live_tuples
FROM pg_stat_user_tables
WHERE schemaname = 'public'
ORDER BY n_live_tup DESC;
```

---

## Migra√ß√µes

As migra√ß√µes s√£o gerenciadas pelo **Alembic**.

### Comandos B√°sicos

```bash
# Acessar diret√≥rio do backend
cd backend

# Criar nova migra√ß√£o (auto-detecta mudan√ßas nos models)
alembic revision --autogenerate -m "descri√ß√£o da mudan√ßa"

# Criar migra√ß√£o vazia (manual)
alembic revision -m "descri√ß√£o"

# Aplicar todas as migra√ß√µes pendentes
alembic upgrade head

# Aplicar migra√ß√£o espec√≠fica
alembic upgrade <revision_id>

# Reverter √∫ltima migra√ß√£o
alembic downgrade -1

# Reverter todas as migra√ß√µes
alembic downgrade base

# Ver hist√≥rico de migra√ß√µes
alembic history

# Ver migra√ß√£o atual
alembic current

# Ver SQL que ser√° executado (sem executar)
alembic upgrade head --sql
```

### Estrutura de Migra√ß√£o

```python
"""adiciona_campo_metadata_em_alerts

Revision ID: abc123def456
Revises: prev_revision_id
Create Date: 2024-01-15 10:30:00.000000

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = 'abc123def456'
down_revision = 'prev_revision_id'
branch_labels = None
depends_on = None


def upgrade():
    # Adicionar coluna
    op.add_column('alerts', 
        sa.Column('metadata', postgresql.JSONB, nullable=True, server_default='{}')
    )
    
    # Criar √≠ndice
    op.create_index('idx_alerts_metadata', 'alerts', ['metadata'], postgresql_using='gin')


def downgrade():
    # Reverter mudan√ßas
    op.drop_index('idx_alerts_metadata', table_name='alerts')
    op.drop_column('alerts', 'metadata')
```

### Boas Pr√°ticas de Migra√ß√£o

**‚úÖ Fa√ßa:**
- Sempre revisar o c√≥digo gerado antes de aplicar
- Testar em ambiente de desenvolvimento primeiro
- Fazer backup antes de aplicar em produ√ß√£o
- Incluir `downgrade()` para reverter se necess√°rio
- Usar nomes descritivos para migra√ß√µes

**‚ùå N√£o Fa√ßa:**
- Editar migra√ß√µes j√° aplicadas
- Deletar arquivos de migra√ß√£o
- Aplicar diretamente em produ√ß√£o sem testar
- Pular migra√ß√µes no hist√≥rico

---

## Performance

### √çndices Recomendados

Todos os √≠ndices importantes j√° est√£o definidos nas tabelas acima, mas aqui est√° um resumo:

#### √çndices Prim√°rios
```sql
-- Colunas de chave estrangeira
CREATE INDEX idx_asset_scores_asset_id ON asset_scores(asset_id);
CREATE INDEX idx_price_data_asset_id ON price_data(asset_id);
CREATE INDEX idx_whale_tx_asset_id ON whale_transactions(asset_id);
CREATE INDEX idx_exchange_flows_asset_id ON exchange_flows(asset_id);
CREATE INDEX idx_alerts_asset_id ON alerts(asset_id);
CREATE INDEX idx_narrative_events_asset_id ON narrative_events(asset_id);
CREATE INDEX idx_metric_snapshots_asset_id ON metric_snapshots(asset_id);
```

#### √çndices de Timestamp
```sql
-- Para queries temporais
CREATE INDEX idx_asset_scores_calculated_at ON asset_scores(calculated_at DESC);
CREATE INDEX idx_price_data_recorded_at ON price_data(recorded_at DESC);
CREATE INDEX idx_whale_tx_recorded_at ON whale_transactions(recorded_at DESC);
CREATE INDEX idx_alerts_created_at ON alerts(created_at DESC);
```

#### √çndices Compostos
```sql
-- Para queries que combinam asset + timestamp
CREATE INDEX idx_asset_scores_asset_time ON asset_scores(asset_id, calculated_at DESC);
CREATE INDEX idx_price_data_asset_time ON price_data(asset_id, recorded_at DESC);
CREATE INDEX idx_whale_tx_asset_time ON whale_transactions(asset_id, recorded_at DESC);
```

#### √çndices Parciais
```sql
-- Para consultas frequentes com filtros espec√≠ficos
CREATE INDEX idx_alerts_unread ON alerts(status) WHERE status = 'pending';
CREATE INDEX idx_assets_active ON assets(is_active) WHERE is_active = true;
```

#### √çndices GIN (para JSONB)
```sql
-- Para queries em campos JSONB
CREATE INDEX idx_asset_scores_reasons ON asset_scores USING GIN(reasons);
CREATE INDEX idx_alerts_metadata ON alerts USING GIN(metadata);
CREATE INDEX idx_metric_snapshots_metadata ON metric_snapshots USING GIN(metadata);
```

### An√°lise de Performance

#### Verificar queries lentas
```sql
-- Habilitar log de queries lentas (postgresql.conf)
-- log_min_duration_statement = 1000  # em ms

-- Ver queries mais lentas
SELECT 
    query,
    calls,
    total_time,
    mean_time,
    max_time
FROM pg_stat_statements
ORDER BY mean_time DESC
LIMIT 20;
```

#### Explicar plano de execu√ß√£o
```sql
-- Ver plano de execu√ß√£o de uma query
EXPLAIN ANALYZE
SELECT 
    a.symbol,
    s.explosion_score,
    s.calculated_at
FROM asset_scores s
JOIN assets a ON s.asset_id = a.id
WHERE a.is_active = true
  AND s.calculated_at > NOW() - INTERVAL '24 hours'
ORDER BY s.explosion_score DESC
LIMIT 10;
```

#### Estat√≠sticas de √≠ndices
```sql
-- Ver uso de √≠ndices
SELECT 
    schemaname,
    tablename,
    indexname,
    idx_scan as index_scans,
    idx_tup_read as tuples_read,
    idx_tup_fetch as tuples_fetched
FROM pg_stat_user_indexes
WHERE schemaname = 'public'
ORDER BY idx_scan DESC;

-- Identificar √≠ndices n√£o utilizados
SELECT 
    schemaname,
    tablename,
    indexname
FROM pg_stat_user_indexes
WHERE idx_scan = 0
  AND indexname NOT LIKE '%_pkey'
  AND schemaname = 'public';
```

### Particionamento (Futuro)

Para grandes volumes de dados, considere particionar tabelas por tempo:

```sql
-- Exemplo: Particionar price_data por m√™s
CREATE TABLE price_data (
    id SERIAL,
    asset_id INTEGER NOT NULL,
    price DECIMAL(20,8) NOT NULL,
    volume_24h DECIMAL(30,2),
    market_cap DECIMAL(30,2),
    price_change_24h DECIMAL(10,4),
    recorded_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
) PARTITION BY RANGE (recorded_at);

-- Criar parti√ß√µes mensais
CREATE TABLE price_data_2024_01 PARTITION OF price_data
    FOR VALUES FROM ('2024-01-01') TO ('2024-02-01');

CREATE TABLE price_data_2024_02 PARTITION OF price_data
    FOR VALUES FROM ('2024-02-01') TO ('2024-03-01');

-- E assim por diante...
```

### Connection Pooling

Configure connection pooling no SQLAlchemy (backend):

```python
# backend/src/database/connection.py
from sqlalchemy import create_engine
from sqlalchemy.pool import QueuePool

engine = create_engine(
    DATABASE_URL,
    poolclass=QueuePool,
    pool_size=10,          # Conex√µes permanentes
    max_overflow=20,       # Conex√µes extras sob demanda
    pool_timeout=30,       # Timeout para obter conex√£o
    pool_recycle=3600,     # Reciclar conex√µes ap√≥s 1h
    pool_pre_ping=True     # Verificar conex√µes antes de usar
)
```

### Otimiza√ß√µes de Queries

#### Use EXPLAIN ANALYZE
```sql
-- Sempre use EXPLAIN para entender o plano de execu√ß√£o
EXPLAIN (ANALYZE, BUFFERS, VERBOSE)
SELECT ...
```

#### Limite resultados
```sql
-- Sempre use LIMIT em consultas de listagem
SELECT * FROM price_data 
ORDER BY recorded_at DESC 
LIMIT 100;
```

#### Use √≠ndices apropriados
```sql
-- Ruim: Sem √≠ndice
SELECT * FROM asset_scores WHERE calculated_at > '2024-01-01';

-- Bom: Com √≠ndice
-- J√° existe: idx_asset_scores_calculated_at
```

#### Evite SELECT *
```sql
-- Ruim
SELECT * FROM asset_scores;

-- Bom: Selecione apenas o necess√°rio
SELECT id, asset_id, explosion_score, calculated_at 
FROM asset_scores;
```

---

## Backup e Restore

### Backup Completo

```bash
# Backup completo
pg_dump -U cryptopulse -h localhost cryptopulse > backup.sql

# Backup comprimido
pg_dump -U cryptopulse -h localhost cryptopulse | gzip > backup.sql.gz

# Backup com formato custom (mais flex√≠vel)
pg_dump -U cryptopulse -h localhost -Fc cryptopulse > backup.dump
```

### Backup de Tabelas Espec√≠ficas

```bash
# Apenas tabela de assets
pg_dump -U cryptopulse -h localhost -t assets cryptopulse > assets_backup.sql

# M√∫ltiplas tabelas
pg_dump -U cryptopulse -h localhost -t assets -t asset_scores cryptopulse > tables_backup.sql
```

### Restore

```bash
# Restore completo (SQL)
psql -U cryptopulse -h localhost cryptopulse < backup.sql

# Restore comprimido
gunzip -c backup.sql.gz | psql -U cryptopulse -h localhost cryptopulse

# Restore custom format
pg_restore -U cryptopulse -h localhost -d cryptopulse backup.dump

# Restore de tabela espec√≠fica
pg_restore -U cryptopulse -h localhost -d cryptopulse -t assets backup.dump
```

### Backup Incremental (WAL)

```bash
# Configurar WAL archiving (postgresql.conf)
# wal_level = replica
# archive_mode = on
# archive_command = 'cp %p /path/to/archive/%f'

# Backup base
pg_basebackup -U cryptopulse -h localhost -D /backup/base -Fp -Xs -P

# Recovery usa WAL archives automaticamente
```

---

## Fun√ß√µes e Triggers √öteis

### Fun√ß√£o para atualizar updated_at

```sql
-- Criar fun√ß√£o
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $
BEGIN
    NEW.updated_at = NOW();
    RETURN NEW;
END;
$ language 'plpgsql';

-- Aplicar a assets
CREATE TRIGGER update_assets_updated_at
    BEFORE UPDATE ON assets
    FOR EACH ROW
    EXECUTE FUNCTION update_updated_at_column();
```

### Fun√ß√£o para limpar dados antigos

```sql
-- Fun√ß√£o para deletar dados antigos automaticamente
CREATE OR REPLACE FUNCTION cleanup_old_data()
RETURNS void AS $
BEGIN
    DELETE FROM price_data WHERE recorded_at < NOW() - INTERVAL '90 days';
    DELETE FROM asset_scores WHERE calculated_at < NOW() - INTERVAL '30 days';
    DELETE FROM alerts WHERE status IN ('read', 'dismissed') AND read_at < NOW() - INTERVAL '7 days';
    DELETE FROM whale_transactions WHERE recorded_at < NOW() - INTERVAL '60 days';
    DELETE FROM narrative_events WHERE recorded_at < NOW() - INTERVAL '30 days';
    
    RAISE NOTICE 'Old data cleaned up successfully';
END;
$ LANGUAGE plpgsql;

-- Executar manualmente
SELECT cleanup_old_data();
```

### Trigger para auditoria

```sql
-- Tabela de auditoria
CREATE TABLE audit_log (
    id SERIAL PRIMARY KEY,
    table_name VARCHAR(50),
    operation VARCHAR(10),
    old_data JSONB,
    new_data JSONB,
    changed_by VARCHAR(100),
    changed_at TIMESTAMP DEFAULT NOW()
);

-- Fun√ß√£o de auditoria
CREATE OR REPLACE FUNCTION audit_trigger_func()
RETURNS TRIGGER AS $
BEGIN
    IF (TG_OP = 'DELETE') THEN
        INSERT INTO audit_log (table_name, operation, old_data)
        VALUES (TG_TABLE_NAME, TG_OP, row_to_json(OLD));
        RETURN OLD;
    ELSIF (TG_OP = 'UPDATE') THEN
        INSERT INTO audit_log (table_name, operation, old_data, new_data)
        VALUES (TG_TABLE_NAME, TG_OP, row_to_json(OLD), row_to_json(NEW));
        RETURN NEW;
    ELSIF (TG_OP = 'INSERT') THEN
        INSERT INTO audit_log (table_name, operation, new_data)
        VALUES (TG_TABLE_NAME, TG_OP, row_to_json(NEW));
        RETURN NEW;
    END IF;
END;
$ LANGUAGE plpgsql;

-- Aplicar trigger em tabelas importantes
CREATE TRIGGER audit_assets
    AFTER INSERT OR UPDATE OR DELETE ON assets
    FOR EACH ROW EXECUTE FUNCTION audit_trigger_func();
```

---

## Seguran√ßa

### Roles e Permiss√µes

```sql
-- Criar roles
CREATE ROLE cryptopulse_readonly;
CREATE ROLE cryptopulse_readwrite;
CREATE ROLE cryptopulse_admin;

-- Permiss√µes readonly
GRANT CONNECT ON DATABASE cryptopulse TO cryptopulse_readonly;
GRANT USAGE ON SCHEMA public TO cryptopulse_readonly;
GRANT SELECT ON ALL TABLES IN SCHEMA public TO cryptopulse_readonly;

-- Permiss√µes readwrite
GRANT CONNECT ON DATABASE cryptopulse TO cryptopulse_readwrite;
GRANT USAGE ON SCHEMA public TO cryptopulse_readwrite;
GRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA public TO cryptopulse_readwrite;
GRANT USAGE ON ALL SEQUENCES IN SCHEMA public TO cryptopulse_readwrite;

-- Permiss√µes admin
GRANT ALL PRIVILEGES ON DATABASE cryptopulse TO cryptopulse_admin;

-- Criar usu√°rios
CREATE USER app_user WITH PASSWORD 'secure_password';
GRANT cryptopulse_readwrite TO app_user;

CREATE USER report_user WITH PASSWORD 'secure_password';
GRANT cryptopulse_readonly TO report_user;
```

### Row Level Security (RLS)

```sql
-- Habilitar RLS em uma tabela
ALTER TABLE alerts ENABLE ROW LEVEL SECURITY;

-- Criar pol√≠tica (exemplo: usu√°rios s√≥ veem seus pr√≥prios alertas)
CREATE POLICY alerts_user_policy ON alerts
    FOR SELECT
    USING (created_by = current_user);
```

---

## Monitoramento

### Queries de Monitoramento

```sql
-- Conex√µes ativas
SELECT 
    datname,
    usename,
    application_name,
    client_addr,
    state,
    query_start,
    state_change
FROM pg_stat_activity
WHERE datname = 'cryptopulse';

-- Locks ativos
SELECT 
    locktype,
    relation::regclass,
    mode,
    granted
FROM pg_locks
WHERE NOT granted;

-- Tamanho total do banco
SELECT 
    pg_size_pretty(pg_database_size('cryptopulse')) as database_size;

-- Cache hit ratio (deve ser > 95%)
SELECT 
    sum(heap_blks_read) as heap_read,
    sum(heap_blks_hit) as heap_hit,
    sum(heap_blks_hit) / (sum(heap_blks_hit) + sum(heap_blks_read)) * 100 as cache_hit_ratio
FROM pg_statio_user_tables;
```

---

## Refer√™ncias

- [PostgreSQL Documentation](https://www.postgresql.org/docs/)
- [SQLAlchemy ORM](https://docs.sqlalchemy.org/)
- [Alembic Migrations](https://alembic.sqlalchemy.org/)
- [PostgreSQL Performance](https://wiki.postgresql.org/wiki/Performance_Optimization)

---

üìÖ **√öltima atualiza√ß√£o**: Janeiro 2024  
üìù **Vers√£o**: 1.0.0